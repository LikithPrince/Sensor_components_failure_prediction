{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>ag_003</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056758.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42328.0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50394.0</td>\n",
       "      <td>184552.0</td>\n",
       "      <td>2116260.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1450086.0</td>\n",
       "      <td>713608.0</td>\n",
       "      <td>1750894.0</td>\n",
       "      <td>4054554.0</td>\n",
       "      <td>4096660.0</td>\n",
       "      <td>2295880.0</td>\n",
       "      <td>220478.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1665858.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4210.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15655546.0</td>\n",
       "      <td>7961190.0</td>\n",
       "      <td>15573746.0</td>\n",
       "      <td>13337708.0</td>\n",
       "      <td>9939694.0</td>\n",
       "      <td>6375252.0</td>\n",
       "      <td>6517696.0</td>\n",
       "      <td>180452.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>341116.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>730.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6782.0</td>\n",
       "      <td>243092.0</td>\n",
       "      <td>2693264.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1392970.0</td>\n",
       "      <td>670836.0</td>\n",
       "      <td>1622420.0</td>\n",
       "      <td>2006306.0</td>\n",
       "      <td>5831812.0</td>\n",
       "      <td>3198600.0</td>\n",
       "      <td>47068.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>207292.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34086.0</td>\n",
       "      <td>300110.0</td>\n",
       "      <td>2063184.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1075284.0</td>\n",
       "      <td>748704.0</td>\n",
       "      <td>1892554.0</td>\n",
       "      <td>2372806.0</td>\n",
       "      <td>3308370.0</td>\n",
       "      <td>176844.0</td>\n",
       "      <td>4860.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1386134.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37938.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11849780.0</td>\n",
       "      <td>6078744.0</td>\n",
       "      <td>11391988.0</td>\n",
       "      <td>9705102.0</td>\n",
       "      <td>10601346.0</td>\n",
       "      <td>5264516.0</td>\n",
       "      <td>6692608.0</td>\n",
       "      <td>634500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aa_000  ab_000   ac_000  ad_000  ae_000  af_000  ag_000   ag_001  \\\n",
       "0  1056758.0     0.0  42328.0   856.0     0.0     0.0     0.0  50394.0   \n",
       "1  1665858.0     NaN      NaN     NaN     0.0     0.0     0.0      0.0   \n",
       "2   341116.0     NaN    730.0     NaN     0.0     0.0     0.0   6782.0   \n",
       "3   207292.0     NaN   3418.0     NaN     0.0     0.0     0.0  34086.0   \n",
       "4  1386134.0     NaN      0.0     NaN     0.0     0.0     0.0      0.0   \n",
       "\n",
       "     ag_002     ag_003  ...      ee_002     ee_003      ee_004      ee_005  \\\n",
       "0  184552.0  2116260.0  ...   1450086.0   713608.0   1750894.0   4054554.0   \n",
       "1       0.0     4210.0  ...  15655546.0  7961190.0  15573746.0  13337708.0   \n",
       "2  243092.0  2693264.0  ...   1392970.0   670836.0   1622420.0   2006306.0   \n",
       "3  300110.0  2063184.0  ...   1075284.0   748704.0   1892554.0   2372806.0   \n",
       "4       0.0    37938.0  ...  11849780.0  6078744.0  11391988.0   9705102.0   \n",
       "\n",
       "       ee_006     ee_007     ee_008    ee_009  ef_000  eg_000  \n",
       "0   4096660.0  2295880.0   220478.0     482.0     0.0     0.0  \n",
       "1   9939694.0  6375252.0  6517696.0  180452.0     0.0     0.0  \n",
       "2   5831812.0  3198600.0    47068.0       0.0     0.0     0.0  \n",
       "3   3308370.0   176844.0     4860.0       0.0     0.0     0.0  \n",
       "4  10601346.0  5264516.0  6692608.0  634500.0     0.0     0.0  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/sensor.csv', na_values='na')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35002 entries, 0 to 35001\n",
      "Columns: 171 entries, aa_000 to eg_000\n",
      "dtypes: float64(170), object(1)\n",
      "memory usage: 45.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = [col for col in df.columns if df[col].dtype != 'O']\n",
    "target_columns = [col for col in df.columns if df[col].dtype == 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa_000',\n",
       " 'ab_000',\n",
       " 'ac_000',\n",
       " 'ad_000',\n",
       " 'ae_000',\n",
       " 'af_000',\n",
       " 'ag_000',\n",
       " 'ag_001',\n",
       " 'ag_002',\n",
       " 'ag_003',\n",
       " 'ag_004',\n",
       " 'ag_005',\n",
       " 'ag_006',\n",
       " 'ag_007',\n",
       " 'ag_008',\n",
       " 'ag_009',\n",
       " 'ah_000',\n",
       " 'ai_000',\n",
       " 'aj_000',\n",
       " 'ak_000',\n",
       " 'al_000',\n",
       " 'am_0',\n",
       " 'an_000',\n",
       " 'ao_000',\n",
       " 'ap_000',\n",
       " 'aq_000',\n",
       " 'ar_000',\n",
       " 'as_000',\n",
       " 'at_000',\n",
       " 'au_000',\n",
       " 'av_000',\n",
       " 'ax_000',\n",
       " 'ay_000',\n",
       " 'ay_001',\n",
       " 'ay_002',\n",
       " 'ay_003',\n",
       " 'ay_004',\n",
       " 'ay_005',\n",
       " 'ay_006',\n",
       " 'ay_007',\n",
       " 'ay_008',\n",
       " 'ay_009',\n",
       " 'az_000',\n",
       " 'az_001',\n",
       " 'az_002',\n",
       " 'az_003',\n",
       " 'az_004',\n",
       " 'az_005',\n",
       " 'az_006',\n",
       " 'az_007',\n",
       " 'az_008',\n",
       " 'az_009',\n",
       " 'ba_000',\n",
       " 'ba_001',\n",
       " 'ba_002',\n",
       " 'ba_003',\n",
       " 'ba_004',\n",
       " 'ba_005',\n",
       " 'ba_006',\n",
       " 'ba_007',\n",
       " 'ba_008',\n",
       " 'ba_009',\n",
       " 'bb_000',\n",
       " 'bc_000',\n",
       " 'bd_000',\n",
       " 'be_000',\n",
       " 'bf_000',\n",
       " 'bg_000',\n",
       " 'bh_000',\n",
       " 'bi_000',\n",
       " 'bj_000',\n",
       " 'bk_000',\n",
       " 'bl_000',\n",
       " 'bm_000',\n",
       " 'bn_000',\n",
       " 'bo_000',\n",
       " 'bp_000',\n",
       " 'bq_000',\n",
       " 'br_000',\n",
       " 'bs_000',\n",
       " 'bt_000',\n",
       " 'bu_000',\n",
       " 'bv_000',\n",
       " 'bx_000',\n",
       " 'by_000',\n",
       " 'bz_000',\n",
       " 'ca_000',\n",
       " 'cb_000',\n",
       " 'cc_000',\n",
       " 'cd_000',\n",
       " 'ce_000',\n",
       " 'cf_000',\n",
       " 'cg_000',\n",
       " 'ch_000',\n",
       " 'ci_000',\n",
       " 'cj_000',\n",
       " 'ck_000',\n",
       " 'cl_000',\n",
       " 'cm_000',\n",
       " 'cn_000',\n",
       " 'cn_001',\n",
       " 'cn_002',\n",
       " 'cn_003',\n",
       " 'cn_004',\n",
       " 'cn_005',\n",
       " 'cn_006',\n",
       " 'cn_007',\n",
       " 'cn_008',\n",
       " 'cn_009',\n",
       " 'co_000',\n",
       " 'cp_000',\n",
       " 'cq_000',\n",
       " 'cr_000',\n",
       " 'cs_000',\n",
       " 'cs_001',\n",
       " 'cs_002',\n",
       " 'cs_003',\n",
       " 'cs_004',\n",
       " 'cs_005',\n",
       " 'cs_006',\n",
       " 'cs_007',\n",
       " 'cs_008',\n",
       " 'cs_009',\n",
       " 'ct_000',\n",
       " 'cu_000',\n",
       " 'cv_000',\n",
       " 'cx_000',\n",
       " 'cy_000',\n",
       " 'cz_000',\n",
       " 'da_000',\n",
       " 'db_000',\n",
       " 'dc_000',\n",
       " 'dd_000',\n",
       " 'de_000',\n",
       " 'df_000',\n",
       " 'dg_000',\n",
       " 'dh_000',\n",
       " 'di_000',\n",
       " 'dj_000',\n",
       " 'dk_000',\n",
       " 'dl_000',\n",
       " 'dm_000',\n",
       " 'dn_000',\n",
       " 'do_000',\n",
       " 'dp_000',\n",
       " 'dq_000',\n",
       " 'dr_000',\n",
       " 'ds_000',\n",
       " 'dt_000',\n",
       " 'du_000',\n",
       " 'dv_000',\n",
       " 'dx_000',\n",
       " 'dy_000',\n",
       " 'dz_000',\n",
       " 'ea_000',\n",
       " 'eb_000',\n",
       " 'ec_00',\n",
       " 'ed_000',\n",
       " 'ee_000',\n",
       " 'ee_001',\n",
       " 'ee_002',\n",
       " 'ee_003',\n",
       " 'ee_004',\n",
       " 'ee_005',\n",
       " 'ee_006',\n",
       " 'ee_007',\n",
       " 'ee_008',\n",
       " 'ee_009',\n",
       " 'ef_000',\n",
       " 'eg_000']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['class']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "neg      34020\n",
       "pos        981\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the imbalance of target column\n",
    "df[target_columns].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='class'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAHMCAYAAADcawJZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAz2UlEQVR4nO3df3BU9b3/8dcSyBJisk0I+bElIr1ACg1aG5AEvBUFEhhCoDqF2zhbcsWgReCmkItiry12FFBUtHJL0XpFEI3ei7HW4JpYC5qS8CPTtAYBqQUJkh8IywbSdBPD+f7hcL4uwR/h1yYfno+ZM5M9533Ovj8Zwr72s+ecdViWZQkAAMBAPULdAAAAwMVC0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGKtnqBsIpVOnTunw4cOKioqSw+EIdTsAAOBrsCxLJ06ckNvtVo8eXz5nc1kHncOHDys5OTnUbQAAgHNQW1ur/v37f2nNZR10oqKiJH32i4qOjg5xNwAA4OtoampScnKy/Tr+ZS7roHP646ro6GiCDgAA3czXOe2kUycjr169WldffbUdDDIyMvTGG2/Y2/Py8uRwOIKW9PT0oGMEAgHNmzdPcXFxioyMVE5Ojg4dOhRU4/P55PF45HK55HK55PF4dPz48aCagwcPasqUKYqMjFRcXJzmz5+v1tbWzgwHAAAYrlNBp3///lq+fLl27typnTt36qabbtLUqVO1a9cuu2bixImqq6uzl02bNgUdo6CgQMXFxSoqKlJ5eblOnjyp7Oxstbe32zW5ubmqrq6W1+uV1+tVdXW1PB6Pvb29vV2TJ09Wc3OzysvLVVRUpI0bN2rhwoXn+nsAAAAmss5TTEyM9dvf/tayLMuaOXOmNXXq1C+sPX78uNWrVy+rqKjIXvfxxx9bPXr0sLxer2VZlvX+++9bkqzKykq7pqKiwpJk7dmzx7Isy9q0aZPVo0cP6+OPP7ZrXnzxRcvpdFp+v/9r9+73+y1JndoHAACEVmdev8/5Pjrt7e0qKipSc3OzMjIy7PWbN29WfHy8hgwZovz8fDU2Ntrbqqqq1NbWpszMTHud2+1Wamqqtm7dKkmqqKiQy+XSqFGj7Jr09HS5XK6gmtTUVLndbrsmKytLgUBAVVVVX9hzIBBQU1NT0AIAAMzV6aDz3nvv6YorrpDT6dSdd96p4uJiDRs2TJI0adIkbdiwQW+//bYeffRR7dixQzfddJMCgYAkqb6+XuHh4YqJiQk6ZkJCgurr6+2a+Pj4Ds8bHx8fVJOQkBC0PSYmRuHh4XbN2Sxbtsw+78flcnFpOQAAhuv0VVcpKSmqrq7W8ePHtXHjRs2cOVNbtmzRsGHDNGPGDLsuNTVVI0aM0IABA1RSUqKbb775C49pWVbQmdNnO4v6XGrOtHjxYi1YsMB+fPryNAAAYKZOz+iEh4dr0KBBGjFihJYtW6ZrrrlGTzzxxFlrk5KSNGDAAO3bt0+SlJiYqNbWVvl8vqC6xsZGe4YmMTFRDQ0NHY515MiRoJozZ258Pp/a2to6zPR8ntPptK8Y45JyAADMd97fdWVZlv3R1JmOHj2q2tpaJSUlSZLS0tLUq1cvlZWV2TV1dXWqqanR6NGjJUkZGRny+/3avn27XbNt2zb5/f6gmpqaGtXV1dk1paWlcjqdSktLO98hAQAAQzgsy7K+bvG9996rSZMmKTk5WSdOnFBRUZGWL18ur9erjIwMLVmyRLfccouSkpJ04MAB3XvvvTp48KB2795t373wJz/5iV5//XWtXbtWsbGxKiws1NGjR1VVVaWwsDBJn53rc/jwYa1Zs0aSNHv2bA0YMEC///3vJX12IvR3v/tdJSQkaMWKFTp27Jjy8vI0bdo0Pfnkk1978E1NTXK5XPL7/czuAADQTXTm9btT5+g0NDTI4/Gorq5OLpdLV199tbxeryZMmKCWlha99957WrdunY4fP66kpCTdeOONeumll4Ju0bxy5Ur17NlT06dPV0tLi8aNG6e1a9faIUeSNmzYoPnz59tXZ+Xk5GjVqlX29rCwMJWUlGjOnDkaM2aMIiIilJubq0ceeaQzwwEAAIbr1IyOaZjRAQCg++nM6/d5n6MDAADQVRF0AACAsQg6AADAWJ2+YSDMcNU9JaFuAZfQgeWTQ90CAIQEMzoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjNWpoLN69WpdffXVio6OVnR0tDIyMvTGG2/Y2y3L0pIlS+R2uxUREaGxY8dq165dQccIBAKaN2+e4uLiFBkZqZycHB06dCioxufzyePxyOVyyeVyyePx6Pjx40E1Bw8e1JQpUxQZGam4uDjNnz9fra2tnRw+AAAwWaeCTv/+/bV8+XLt3LlTO3fu1E033aSpU6faYebhhx/WY489plWrVmnHjh1KTEzUhAkTdOLECfsYBQUFKi4uVlFRkcrLy3Xy5EllZ2ervb3drsnNzVV1dbW8Xq+8Xq+qq6vl8Xjs7e3t7Zo8ebKam5tVXl6uoqIibdy4UQsXLjzf3wcAADCIw7Is63wOEBsbqxUrVui2226T2+1WQUGB7r77bkmfzd4kJCTooYce0h133CG/369+/fpp/fr1mjFjhiTp8OHDSk5O1qZNm5SVlaXdu3dr2LBhqqys1KhRoyRJlZWVysjI0J49e5SSkqI33nhD2dnZqq2tldvtliQVFRUpLy9PjY2Nio6O/lq9NzU1yeVyye/3f+19THHVPSWhbgGX0IHlk0PdAgBcMJ15/T7nc3Ta29tVVFSk5uZmZWRkaP/+/aqvr1dmZqZd43Q6dcMNN2jr1q2SpKqqKrW1tQXVuN1upaam2jUVFRVyuVx2yJGk9PR0uVyuoJrU1FQ75EhSVlaWAoGAqqqqvrDnQCCgpqamoAUAAJir00Hnvffe0xVXXCGn06k777xTxcXFGjZsmOrr6yVJCQkJQfUJCQn2tvr6eoWHhysmJuZLa+Lj4zs8b3x8fFDNmc8TExOj8PBwu+Zsli1bZp/343K5lJyc3MnRAwCA7qTTQSclJUXV1dWqrKzUT37yE82cOVPvv/++vd3hcATVW5bVYd2Zzqw5W/251Jxp8eLF8vv99lJbW/ulfQEAgO6t00EnPDxcgwYN0ogRI7Rs2TJdc801euKJJ5SYmChJHWZUGhsb7dmXxMREtba2yufzfWlNQ0NDh+c9cuRIUM2Zz+Pz+dTW1tZhpufznE6nfcXY6QUAAJjrvO+jY1mWAoGABg4cqMTERJWVldnbWltbtWXLFo0ePVqSlJaWpl69egXV1NXVqaamxq7JyMiQ3+/X9u3b7Zpt27bJ7/cH1dTU1Kiurs6uKS0tldPpVFpa2vkOCQAAGKJnZ4rvvfdeTZo0ScnJyTpx4oSKioq0efNmeb1eORwOFRQUaOnSpRo8eLAGDx6spUuXqk+fPsrNzZUkuVwuzZo1SwsXLlTfvn0VGxurwsJCDR8+XOPHj5ckDR06VBMnTlR+fr7WrFkjSZo9e7ays7OVkpIiScrMzNSwYcPk8Xi0YsUKHTt2TIWFhcrPz2eWBgAA2DoVdBoaGuTxeFRXVyeXy6Wrr75aXq9XEyZMkCQtWrRILS0tmjNnjnw+n0aNGqXS0lJFRUXZx1i5cqV69uyp6dOnq6WlRePGjdPatWsVFhZm12zYsEHz58+3r87KycnRqlWr7O1hYWEqKSnRnDlzNGbMGEVERCg3N1ePPPLIef0yAACAWc77PjrdGffRweWC++gAMMkluY8OAABAV0fQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABirU0Fn2bJlGjlypKKiohQfH69p06Zp7969QTV5eXlyOBxBS3p6elBNIBDQvHnzFBcXp8jISOXk5OjQoUNBNT6fTx6PRy6XSy6XSx6PR8ePHw+qOXjwoKZMmaLIyEjFxcVp/vz5am1t7cyQAACAwToVdLZs2aK77rpLlZWVKisr06effqrMzEw1NzcH1U2cOFF1dXX2smnTpqDtBQUFKi4uVlFRkcrLy3Xy5EllZ2ervb3drsnNzVV1dbW8Xq+8Xq+qq6vl8Xjs7e3t7Zo8ebKam5tVXl6uoqIibdy4UQsXLjyX3wMAADBQz84Ue73eoMfPPvus4uPjVVVVpe9///v2eqfTqcTExLMew+/365lnntH69es1fvx4SdLzzz+v5ORkvfXWW8rKytLu3bvl9XpVWVmpUaNGSZKefvppZWRkaO/evUpJSVFpaanef/991dbWyu12S5IeffRR5eXl6cEHH1R0dHRnhgYAAAx0Xufo+P1+SVJsbGzQ+s2bNys+Pl5DhgxRfn6+Ghsb7W1VVVVqa2tTZmamvc7tdis1NVVbt26VJFVUVMjlctkhR5LS09PlcrmCalJTU+2QI0lZWVkKBAKqqqo6n2EBAABDdGpG5/Msy9KCBQt0/fXXKzU11V4/adIk/fCHP9SAAQO0f/9+3XfffbrppptUVVUlp9Op+vp6hYeHKyYmJuh4CQkJqq+vlyTV19crPj6+w3PGx8cH1SQkJARtj4mJUXh4uF1zpkAgoEAgYD9uamo6t8EDAIBu4ZyDzty5c/XXv/5V5eXlQetnzJhh/5yamqoRI0ZowIABKikp0c033/yFx7MsSw6Hw378+Z/Pp+bzli1bpvvvv/+LBwUAAIxyTh9dzZs3T6+99pr++Mc/qn///l9am5SUpAEDBmjfvn2SpMTERLW2tsrn8wXVNTY22jM0iYmJamho6HCsI0eOBNWcOXPj8/nU1tbWYabntMWLF8vv99tLbW3t1xswAADoljoVdCzL0ty5c/XKK6/o7bff1sCBA79yn6NHj6q2tlZJSUmSpLS0NPXq1UtlZWV2TV1dnWpqajR69GhJUkZGhvx+v7Zv327XbNu2TX6/P6impqZGdXV1dk1paamcTqfS0tLO2ovT6VR0dHTQAgAAzNWpj67uuusuvfDCC/rd736nqKgoe0bF5XIpIiJCJ0+e1JIlS3TLLbcoKSlJBw4c0L333qu4uDj94Ac/sGtnzZqlhQsXqm/fvoqNjVVhYaGGDx9uX4U1dOhQTZw4Ufn5+VqzZo0kafbs2crOzlZKSookKTMzU8OGDZPH49GKFSt07NgxFRYWKj8/nwADAAAkdXJGZ/Xq1fL7/Ro7dqySkpLs5aWXXpIkhYWF6b333tPUqVM1ZMgQzZw5U0OGDFFFRYWioqLs46xcuVLTpk3T9OnTNWbMGPXp00e///3vFRYWZtds2LBBw4cPV2ZmpjIzM3X11Vdr/fr19vawsDCVlJSod+/eGjNmjKZPn65p06bpkUceOd/fCQAAMITDsiwr1E2ESlNTk1wul/x+/2U3C3TVPSWhbgGX0IHlk0PdAgBcMJ15/ea7rgAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxOhV0li1bppEjRyoqKkrx8fGaNm2a9u7dG1RjWZaWLFkit9utiIgIjR07Vrt27QqqCQQCmjdvnuLi4hQZGamcnBwdOnQoqMbn88nj8cjlcsnlcsnj8ej48eNBNQcPHtSUKVMUGRmpuLg4zZ8/X62trZ0ZEgAAMFings6WLVt01113qbKyUmVlZfr000+VmZmp5uZmu+bhhx/WY489plWrVmnHjh1KTEzUhAkTdOLECbumoKBAxcXFKioqUnl5uU6ePKns7Gy1t7fbNbm5uaqurpbX65XX61V1dbU8Ho+9vb29XZMnT1Zzc7PKy8tVVFSkjRs3auHChefz+wAAAAZxWJZlnevOR44cUXx8vLZs2aLvf//7sixLbrdbBQUFuvvuuyV9NnuTkJCghx56SHfccYf8fr/69eun9evXa8aMGZKkw4cPKzk5WZs2bVJWVpZ2796tYcOGqbKyUqNGjZIkVVZWKiMjQ3v27FFKSoreeOMNZWdnq7a2Vm63W5JUVFSkvLw8NTY2Kjo6+iv7b2pqksvlkt/v/1r1JrnqnpJQt4BL6MDyyaFuAQAumM68fp/XOTp+v1+SFBsbK0nav3+/6uvrlZmZadc4nU7dcMMN2rp1qySpqqpKbW1tQTVut1upqal2TUVFhVwulx1yJCk9PV0ulyuoJjU11Q45kpSVlaVAIKCqqqqz9hsIBNTU1BS0AAAAc51z0LEsSwsWLND111+v1NRUSVJ9fb0kKSEhIag2ISHB3lZfX6/w8HDFxMR8aU18fHyH54yPjw+qOfN5YmJiFB4ebtecadmyZfY5Py6XS8nJyZ0dNgAA6EbOOejMnTtXf/3rX/Xiiy922OZwOIIeW5bVYd2Zzqw5W/251Hze4sWL5ff77aW2tvZLewIAAN3bOQWdefPm6bXXXtMf//hH9e/f316fmJgoSR1mVBobG+3Zl8TERLW2tsrn831pTUNDQ4fnPXLkSFDNmc/j8/nU1tbWYabnNKfTqejo6KAFAACYq1NBx7IszZ07V6+88orefvttDRw4MGj7wIEDlZiYqLKyMntda2urtmzZotGjR0uS0tLS1KtXr6Cauro61dTU2DUZGRny+/3avn27XbNt2zb5/f6gmpqaGtXV1dk1paWlcjqdSktL68ywAACAoXp2pviuu+7SCy+8oN/97neKioqyZ1RcLpciIiLkcDhUUFCgpUuXavDgwRo8eLCWLl2qPn36KDc3166dNWuWFi5cqL59+yo2NlaFhYUaPny4xo8fL0kaOnSoJk6cqPz8fK1Zs0aSNHv2bGVnZyslJUWSlJmZqWHDhsnj8WjFihU6duyYCgsLlZ+fz0wNAACQ1Mmgs3r1aknS2LFjg9Y/++yzysvLkyQtWrRILS0tmjNnjnw+n0aNGqXS0lJFRUXZ9StXrlTPnj01ffp0tbS0aNy4cVq7dq3CwsLsmg0bNmj+/Pn21Vk5OTlatWqVvT0sLEwlJSWaM2eOxowZo4iICOXm5uqRRx7p1C8AAACY67zuo9PdcR8dXC64jw4Ak1yy++gAAAB0ZQQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFidDjrvvPOOpkyZIrfbLYfDoVdffTVoe15enhwOR9CSnp4eVBMIBDRv3jzFxcUpMjJSOTk5OnToUFCNz+eTx+ORy+WSy+WSx+PR8ePHg2oOHjyoKVOmKDIyUnFxcZo/f75aW1s7OyQAAGCoTged5uZmXXPNNVq1atUX1kycOFF1dXX2smnTpqDtBQUFKi4uVlFRkcrLy3Xy5EllZ2ervb3drsnNzVV1dbW8Xq+8Xq+qq6vl8Xjs7e3t7Zo8ebKam5tVXl6uoqIibdy4UQsXLuzskAAAgKF6dnaHSZMmadKkSV9a43Q6lZiYeNZtfr9fzzzzjNavX6/x48dLkp5//nklJyfrrbfeUlZWlnbv3i2v16vKykqNGjVKkvT0008rIyNDe/fuVUpKikpLS/X++++rtrZWbrdbkvToo48qLy9PDz74oKKjozs7NAAAYJiLco7O5s2bFR8fryFDhig/P1+NjY32tqqqKrW1tSkzM9Ne53a7lZqaqq1bt0qSKioq5HK57JAjSenp6XK5XEE1qampdsiRpKysLAUCAVVVVZ21r0AgoKampqAFAACY64IHnUmTJmnDhg16++239eijj2rHjh266aabFAgEJEn19fUKDw9XTExM0H4JCQmqr6+3a+Lj4zscOz4+PqgmISEhaHtMTIzCw8PtmjMtW7bMPufH5XIpOTn5vMcLAAC6rk5/dPVVZsyYYf+cmpqqESNGaMCAASopKdHNN9/8hftZliWHw2E//vzP51PzeYsXL9aCBQvsx01NTYQdAAAMdtEvL09KStKAAQO0b98+SVJiYqJaW1vl8/mC6hobG+0ZmsTERDU0NHQ41pEjR4Jqzpy58fl8amtr6zDTc5rT6VR0dHTQAgAAzHXRg87Ro0dVW1urpKQkSVJaWpp69eqlsrIyu6aurk41NTUaPXq0JCkjI0N+v1/bt2+3a7Zt2ya/3x9UU1NTo7q6OrumtLRUTqdTaWlpF3tYAACgG+j0R1cnT57U3/72N/vx/v37VV1drdjYWMXGxmrJkiW65ZZblJSUpAMHDujee+9VXFycfvCDH0iSXC6XZs2apYULF6pv376KjY1VYWGhhg8fbl+FNXToUE2cOFH5+flas2aNJGn27NnKzs5WSkqKJCkzM1PDhg2Tx+PRihUrdOzYMRUWFio/P5+ZGgAAIOkcgs7OnTt144032o9Pn/Myc+ZMrV69Wu+9957WrVun48ePKykpSTfeeKNeeuklRUVF2fusXLlSPXv21PTp09XS0qJx48Zp7dq1CgsLs2s2bNig+fPn21dn5eTkBN27JywsTCUlJZozZ47GjBmjiIgI5ebm6pFHHun8bwEAABjJYVmWFeomQqWpqUkul0t+v/+ymwW66p6SULeAS+jA8smhbgEALpjOvH7zXVcAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWJ0OOu+8846mTJkit9sth8OhV199NWi7ZVlasmSJ3G63IiIiNHbsWO3atSuoJhAIaN68eYqLi1NkZKRycnJ06NChoBqfzyePxyOXyyWXyyWPx6Pjx48H1Rw8eFBTpkxRZGSk4uLiNH/+fLW2tnZ2SAAAwFCdDjrNzc265pprtGrVqrNuf/jhh/XYY49p1apV2rFjhxITEzVhwgSdOHHCrikoKFBxcbGKiopUXl6ukydPKjs7W+3t7XZNbm6uqqur5fV65fV6VV1dLY/HY29vb2/X5MmT1dzcrPLychUVFWnjxo1auHBhZ4cEAAAM5bAsyzrnnR0OFRcXa9q0aZI+m81xu90qKCjQ3XffLemz2ZuEhAQ99NBDuuOOO+T3+9WvXz+tX79eM2bMkCQdPnxYycnJ2rRpk7KysrR7924NGzZMlZWVGjVqlCSpsrJSGRkZ2rNnj1JSUvTGG28oOztbtbW1crvdkqSioiLl5eWpsbFR0dHRX9l/U1OTXC6X/H7/16o3yVX3lIS6BVxCB5ZPDnULAHDBdOb1+4Keo7N//37V19crMzPTXud0OnXDDTdo69atkqSqqiq1tbUF1bjdbqWmpto1FRUVcrlcdsiRpPT0dLlcrqCa1NRUO+RIUlZWlgKBgKqqqs7aXyAQUFNTU9ACAADMdUGDTn19vSQpISEhaH1CQoK9rb6+XuHh4YqJifnSmvj4+A7Hj4+PD6o583liYmIUHh5u15xp2bJl9jk/LpdLycnJ5zBKAADQXVyUq64cDkfQY8uyOqw705k1Z6s/l5rPW7x4sfx+v73U1tZ+aU8AAKB7u6BBJzExUZI6zKg0Njbasy+JiYlqbW2Vz+f70pqGhoYOxz9y5EhQzZnP4/P51NbW1mGm5zSn06no6OigBQAAmOuCBp2BAwcqMTFRZWVl9rrW1lZt2bJFo0ePliSlpaWpV69eQTV1dXWqqamxazIyMuT3+7V9+3a7Ztu2bfL7/UE1NTU1qqurs2tKS0vldDqVlpZ2IYcFAAC6qZ6d3eHkyZP629/+Zj/ev3+/qqurFRsbqyuvvFIFBQVaunSpBg8erMGDB2vp0qXq06ePcnNzJUkul0uzZs3SwoUL1bdvX8XGxqqwsFDDhw/X+PHjJUlDhw7VxIkTlZ+frzVr1kiSZs+erezsbKWkpEiSMjMzNWzYMHk8Hq1YsULHjh1TYWGh8vPzmakBAACSziHo7Ny5UzfeeKP9eMGCBZKkmTNnau3atVq0aJFaWlo0Z84c+Xw+jRo1SqWlpYqKirL3WblypXr27Knp06erpaVF48aN09q1axUWFmbXbNiwQfPnz7evzsrJyQm6d09YWJhKSko0Z84cjRkzRhEREcrNzdUjjzzS+d8CAAAw0nndR6e74z46uFxwHx0AJgnZfXQAAAC6EoIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgXPOgsWbJEDocjaElMTLS3W5alJUuWyO12KyIiQmPHjtWuXbuCjhEIBDRv3jzFxcUpMjJSOTk5OnToUFCNz+eTx+ORy+WSy+WSx+PR8ePHL/RwAABAN3ZRZnS+853vqK6uzl7ee+89e9vDDz+sxx57TKtWrdKOHTuUmJioCRMm6MSJE3ZNQUGBiouLVVRUpPLycp08eVLZ2dlqb2+3a3Jzc1VdXS2v1yuv16vq6mp5PJ6LMRwAANBN9bwoB+3ZM2gW5zTLsvT444/rZz/7mW6++WZJ0nPPPaeEhAS98MILuuOOO+T3+/XMM89o/fr1Gj9+vCTp+eefV3Jyst566y1lZWVp9+7d8nq9qqys1KhRoyRJTz/9tDIyMrR3716lpKRcjGEBAIBu5qLM6Ozbt09ut1sDBw7Uv/3bv+nvf/+7JGn//v2qr69XZmamXet0OnXDDTdo69atkqSqqiq1tbUF1bjdbqWmpto1FRUVcrlcdsiRpPT0dLlcLrsGAADggs/ojBo1SuvWrdOQIUPU0NCgBx54QKNHj9auXbtUX18vSUpISAjaJyEhQR999JEkqb6+XuHh4YqJielQc3r/+vp6xcfHd3ju+Ph4u+ZsAoGAAoGA/bipqencBgkAALqFCx50Jk2aZP88fPhwZWRk6F/+5V/03HPPKT09XZLkcDiC9rEsq8O6M51Zc7b6rzrOsmXLdP/993+tcQAAgO7vol9eHhkZqeHDh2vfvn32eTtnzro0NjbaszyJiYlqbW2Vz+f70pqGhoYOz3XkyJEOs0Wft3jxYvn9fnupra09r7EBAICu7aIHnUAgoN27dyspKUkDBw5UYmKiysrK7O2tra3asmWLRo8eLUlKS0tTr169gmrq6upUU1Nj12RkZMjv92v79u12zbZt2+T3++2as3E6nYqOjg5aAACAuS74R1eFhYWaMmWKrrzySjU2NuqBBx5QU1OTZs6cKYfDoYKCAi1dulSDBw/W4MGDtXTpUvXp00e5ubmSJJfLpVmzZmnhwoXq27evYmNjVVhYqOHDh9tXYQ0dOlQTJ05Ufn6+1qxZI0maPXu2srOzueIKAADYLnjQOXTokH70ox/pk08+Ub9+/ZSenq7KykoNGDBAkrRo0SK1tLRozpw58vl8GjVqlEpLSxUVFWUfY+XKlerZs6emT5+ulpYWjRs3TmvXrlVYWJhds2HDBs2fP9++OisnJ0erVq260MMBAADdmMOyLCvUTYRKU1OTXC6X/H7/Zfcx1lX3lIS6BVxCB5ZPDnULAHDBdOb1m++6AgAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYCyCDgAAMBZBBwAAGIugAwAAjEXQAQAAxiLoAAAAYxF0AACAsQg6AADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxeoa6AQDAhXXVPSWhbgGX0IHlk0PdQpfGjA4AADAWQQcAABiLoAMAAIxF0AEAAMYi6AAAAGN1+6Dz61//WgMHDlTv3r2Vlpamd999N9QtAQCALqJbB52XXnpJBQUF+tnPfqY///nP+td//VdNmjRJBw8eDHVrAACgC+jWQeexxx7TrFmzdPvtt2vo0KF6/PHHlZycrNWrV4e6NQAA0AV02xsGtra2qqqqSvfcc0/Q+szMTG3duvWs+wQCAQUCAfux3++XJDU1NV28RruoU4F/hLoFXEKX47/xyxl/35eXy/Hv+/SYLcv6ytpuG3Q++eQTtbe3KyEhIWh9QkKC6uvrz7rPsmXLdP/993dYn5ycfFF6BLoK1+Oh7gDAxXI5/32fOHFCLpfrS2u6bdA5zeFwBD22LKvDutMWL16sBQsW2I9PnTqlY8eOqW/fvl+4D8zR1NSk5ORk1dbWKjo6OtTtALiA+Pu+vFiWpRMnTsjtdn9lbbcNOnFxcQoLC+swe9PY2Nhhluc0p9Mpp9MZtO4b3/jGxWoRXVR0dDT/EQKG4u/78vFVMzmndduTkcPDw5WWlqaysrKg9WVlZRo9enSIugIAAF1Jt53RkaQFCxbI4/FoxIgRysjI0FNPPaWDBw/qzjvvDHVrAACgC+jWQWfGjBk6evSofvnLX6qurk6pqanatGmTBgwYEOrW0AU5nU794he/6PDxJYDuj79vfBGH9XWuzQIAAOiGuu05OgAAAF+FoAMAAIxF0AEAAMYi6AAAAGMRdAAAgLEIOgAAwFgEHQAAYKxufcNA4Otoa2tTfX29/vGPf6hfv36KjY0NdUsALoADBw7o3Xff1YEDB+y/72uvvVYZGRnq3bt3qNtDF0HQgZFOnjypDRs26MUXX9T27dsVCATsbf3791dmZqZmz56tkSNHhrBLAOfihRde0K9+9Stt375d8fHx+uY3v6mIiAgdO3ZMH374oXr37q1bb71Vd999N3fKB3dGhnlWrlypBx98UFdddZVycnJ03XXXBf1HWFNTo3fffVfFxcVKT0/Xk08+qcGDB4e6bQBfw/e+9z316NFDeXl5ysnJ0ZVXXhm0PRAIqKKiQkVFRdq4caN+/etf64c//GGIukVXQNCBcX74wx/q5z//uYYPH/6ldYFAQM8884zCw8N1++23X6LuAJyPkpISTZ48+WvVfvLJJ9q/fz8zt5c5gg4AADAWV10BAABjEXRw2brtttu0fv36ULcB4CLo0aOHbrrpJlVVVYW6FYQYH13hsjV27Fh99NFHio6O1l/+8pdQtwPgAlq7dq0++ugjlZaW6k9/+lOo20EIEXRw2du7d69SUlJC3QYA4CIg6AAAjNDU1KS3335bKSkpGjp0aKjbQRdB0IHRXnvttbOudzgc6t27twYNGqSBAwde4q4AXAjTp0/X97//fc2dO1ctLS265pprdODAAVmWpaKiIt1yyy2hbhFdAEEHRuvRo4ccDofO/Gd+ep3D4dD111+vV199VTExMSHqEsC5SExM1JtvvqlrrrlGL7zwgn7xi1/oL3/5i5577jk99dRT+vOf/xzqFtEFcNUVjFZWVqaRI0eqrKxMfr9ffr9fZWVluu666/T666/rnXfe0dGjR1VYWBjqVgF0kt/vt7+7zuv16pZbblGfPn00efJk7du3L8Tdoavgu65gtP/4j//QU089pdGjR9vrxo0bp969e2v27NnatWuXHn/8cd12220h7BLAuUhOTlZFRYViY2Pl9XpVVFQkSfL5fHypJ2wEHRjtww8/VHR0dIf10dHR+vvf/y5JGjx4sD755JNL3RqA81RQUKBbb71VV1xxhQYMGKCxY8dKkt55552v/AoYXD44RwdGu/766xUVFaV169apX79+kqQjR47oxz/+sZqbm/XOO+/orbfe0pw5c/TBBx+EuFsAnbVz507V1tZqwoQJuuKKKyR99n1Y3/jGNzRmzJgQd4eugKADo+3du1dTp07V/v37lZycLIfDoYMHD+pb3/qWfve732nIkCF69dVXdeLECXk8nlC3C+AcnX4pczgcIe4EXQ1BB8azLEtvvvmmPvjgA1mWpW9/+9uaMGGCevTgXHygu1u3bp1WrFhhn3w8ZMgQ/ed//idvXGAj6OCy8c9//lNOp5N3fIAhHnvsMd13332aO3euxowZI8uy9Kc//Un//d//rQceeEA//elPQ90iugCCDox26tQpPfjgg/rNb36jhoYGffDBB/rWt76l++67T1dddZVmzZoV6hYBnKOBAwfq/vvv149//OOg9c8995yWLFmi/fv3h6gzdCXM3cNoDzzwgNauXauHH35Y4eHh9vrhw4frt7/9bQg7A3C+6urqgm4dcdro0aNVV1cXgo7QFRF0YLR169bpqaee0q233qqwsDB7/dVXX609e/aEsDMA52vQoEF6+eWXO6x/6aWXNHjw4BB0hK6I++jAaB9//LEGDRrUYf2pU6fU1tYWgo4AXCj333+/ZsyYoXfeeUdjxoyRw+FQeXm5/vCHP5w1AOHyxIwOjPad73xH7777bof1//u//6trr702BB0BuFBuueUWbdu2TXFxcXr11Vf1yiuvKC4uTtu3b9cPfvCDULeHLoIZHRjtF7/4hTwejz7++GOdOnVKr7zyivbu3at169bp9ddfD3V7AM5TWlqann/++VC3gS6Mq65gvDfffFNLly5VVVWVTp06pe9973v6+c9/rszMzFC3BuA8tbe3q7i4WLt375bD4dDQoUM1depU9ezJ+3h8hqADAOiWampqNHXqVNXX1yslJUWS9MEHH6hfv3567bXX+L4rSCLo4DLR2tqqxsZGnTp1Kmj9lVdeGaKOAJyv9PR0xcfH67nnnlNMTIykz765PC8vT42NjaqoqAhxh+gKCDow2r59+3Tbbbdp69atQesty5LD4VB7e3uIOgNwviIiIrRz50595zvfCVpfU1OjkSNHqqWlJUSdoSvhQ0wYLS8vTz179tTrr7+upKQkvv4BMEhKSooaGho6BJ3Gxsaz3lYClydmdGC0yMhIVVVV6dvf/naoWwFwgW3atEmLFi3SkiVLlJ6eLkmqrKzUL3/5Sy1fvlzXX3+9XRsdHR2qNhFiBB0YbeTIkVq5cmXQf3gAzNCjx/+/Fdzp2drTL2mff8zH1Jc3PrqC0R566CEtWrRIS5cu1fDhw9WrV6+g7bzLA7qvP/7xj6FuAd0AMzow2ul3fGeem8O7PKB7OnjwYKeulvz444/1zW9+8yJ2hK6OGR0YjXd8gFlGjhypnJwc5efn67rrrjtrjd/v18svv6wnnnhCd9xxh+bNm3eJu0RXwowOjMM7PsBcx44d09KlS/U///M/6tWrl0aMGCG3263evXvL5/Pp/fff165duzRixAj913/9lyZNmhTqlhFiBB0YJyEhgXd8gOH++c9/atOmTXr33Xd14MABtbS0KC4uTtdee62ysrKUmpoa6hbRRRB0YBze8QEATiPowFi84wMAEHQAAICxenx1CQAAQPdE0AEAAMYi6AAAAGMRdAB0SwcOHJDD4VB1dXWoWwHQhRF0AACAsQg6AADAWAQdAF3aqVOn9NBDD2nQoEFyOp268sor9eCDD3aoa29v16xZszRw4EBFREQoJSVFTzzxRFDN5s2bdd111ykyMlLf+MY3NGbMGH300UeSpL/85S+68cYbFRUVpejoaKWlpWnnzp2XZIwALh6+1BNAl7Z48WI9/fTTWrlypa6//nrV1dVpz549HepOnTql/v376+WXX1ZcXJy2bt2q2bNnKykpSdOnT9enn36qadOmKT8/Xy+++KJaW1u1fft2+5vtb731Vl177bVavXq1wsLCVF1drV69el3q4QK4wLhhIIAu68SJE+rXr59WrVql22+/PWjbgQMHNHDgQP35z3/Wd7/73bPuf9ddd6mhoUH/93//p2PHjqlv377avHmzbrjhhg610dHRevLJJzVz5syLMRQAIcJHVwC6rN27dysQCGjcuHFfq/43v/mNRowYoX79+umKK67Q008/rYMHD0qSYmNjlZeXp6ysLE2ZMkVPPPGE6urq7H0XLFig22+/XePHj9fy5cv14YcfXpQxAbi0CDoAuqyIiIivXfvyyy/rpz/9qW677TaVlpaqurpa//7v/67W1la75tlnn1VFRYVGjx6tl156SUOGDFFlZaUkacmSJdq1a5cmT56st99+W8OGDVNxcfEFHxOAS4uPrgB0Wf/85z8VGxurX/3qV1/50dW8efP0/vvv6w9/+INdM378eH3yySdfeK+djIwMjRw5Ur/61a86bPvRj36k5uZmvfbaaxd0TAAuLWZ0AHRZvXv31t13361FixZp3bp1+vDDD1VZWalnnnmmQ+2gQYO0c+dOvfnmm/rggw903333aceOHfb2/fv3a/HixaqoqNBHH32k0tJSffDBBxo6dKhaWlo0d+5cbd68WR999JH+9Kc/aceOHRo6dOilHC6Ai4CrrgB0affdd5969uypn//85zp8+LCSkpJ05513dqi78847VV1drRkzZsjhcOhHP/qR5syZozfeeEOS1KdPH+3Zs0fPPfecjh49qqSkJM2dO1d33HGHPv30Ux09elQ//vGP1dDQoLi4ON188826//77L/VwAVxgfHQFAACMxUdXAADAWAQdAABgLIIOAAAwFkEHAAAYi6ADAACMRdABAADGIugAAABjEXQAAICxCDoAAMBYBB0AAGAsgg4AADAWQQcAABjr/wHnL0HTLh60bAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[target_columns].value_counts().plot(kind= 'bar') # this is a biased dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aa_000        1\n",
       "ab_000    26995\n",
       "ac_000     2083\n",
       "ad_000     8921\n",
       "ae_000     1543\n",
       "          ...  \n",
       "ee_007      369\n",
       "ee_008      369\n",
       "ee_009      369\n",
       "ef_000     1685\n",
       "eg_000     1684\n",
       "Length: 171, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking missing values\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa_000</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ab_000</td>\n",
       "      <td>77.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ac_000</td>\n",
       "      <td>5.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ad_000</td>\n",
       "      <td>25.487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ae_000</td>\n",
       "      <td>4.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>ee_007</td>\n",
       "      <td>1.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>ee_008</td>\n",
       "      <td>1.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>ee_009</td>\n",
       "      <td>1.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>ef_000</td>\n",
       "      <td>4.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>eg_000</td>\n",
       "      <td>4.811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index       0\n",
       "0    aa_000   0.003\n",
       "1    ab_000  77.124\n",
       "2    ac_000   5.951\n",
       "3    ad_000  25.487\n",
       "4    ae_000   4.408\n",
       "..      ...     ...\n",
       "166  ee_007   1.054\n",
       "167  ee_008   1.054\n",
       "168  ee_009   1.054\n",
       "169  ef_000   4.814\n",
       "170  eg_000   4.811\n",
       "\n",
       "[171 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(df.isna().sum().div(df.shape[0]).mul(100),3).to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>br_000</td>\n",
       "      <td>81.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>bq_000</td>\n",
       "      <td>80.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>bp_000</td>\n",
       "      <td>78.713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>cr_000</td>\n",
       "      <td>77.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ab_000</td>\n",
       "      <td>77.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>cj_000</td>\n",
       "      <td>0.569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>ci_000</td>\n",
       "      <td>0.569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>bt_000</td>\n",
       "      <td>0.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>class</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa_000</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index       0\n",
       "78   br_000  81.350\n",
       "77   bq_000  80.438\n",
       "76   bp_000  78.713\n",
       "113  cr_000  77.124\n",
       "1    ab_000  77.124\n",
       "..      ...     ...\n",
       "95   cj_000   0.569\n",
       "94   ci_000   0.569\n",
       "80   bt_000   0.240\n",
       "98    class   0.003\n",
       "0    aa_000   0.003\n",
       "\n",
       "[171 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_null_df = (round(df.isna().sum().div(df.shape[0]).mul(100),3)).to_frame().reset_index().sort_values(by=[0], ascending=False)\n",
    "perc_null_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_null_df.rename(columns={'index':'col_name',0:'Perc_nul_val'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['col_name', 'Perc_nul_val'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_null_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_name</th>\n",
       "      <th>Perc_nul_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>br_000</td>\n",
       "      <td>81.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>bq_000</td>\n",
       "      <td>80.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>bp_000</td>\n",
       "      <td>78.713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>cr_000</td>\n",
       "      <td>77.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ab_000</td>\n",
       "      <td>77.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>bo_000</td>\n",
       "      <td>76.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>bn_000</td>\n",
       "      <td>72.702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    col_name  Perc_nul_val\n",
       "78    br_000        81.350\n",
       "77    bq_000        80.438\n",
       "76    bp_000        78.713\n",
       "113   cr_000        77.124\n",
       "1     ab_000        77.124\n",
       "75    bo_000        76.467\n",
       "74    bn_000        72.702"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols = perc_null_df[perc_null_df['Perc_nul_val']>70]\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35002, 171)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(drop_cols['col_name'], axis=1, inplace= True) # axis=1 for column and axis=0 for rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35002, 164)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "309391"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5740328"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.product(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Percentage missing : 5.39%'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Percentage missing : {round(df.isna().sum().sum()/np.product(df.shape)*100,2)}%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univerate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x2038003aca0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 300x300 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "sns.displot(df['ee_004'],color='indianred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [col for col in df.columns if df[col].dtype != 'O']\n",
    "categorical_columns = [col for col in df.columns if df[col].dtype == 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,100))\n",
    "for i, col in enumerate(numerical_columns):\n",
    "    plt.subplot(60,3,i+1)\n",
    "    sns.displot(x=df[col],color='indianred')\n",
    "    plt.xlabel(col, weight = 'bold')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report,ConfusionMatrixDisplay, \\\n",
    "                            precision_score, recall_score, f1_score, roc_auc_score,roc_curve,confusion_matrix\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import  train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler,RobustScaler\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true,predicted):\n",
    "    \"\"\"\n",
    "    This function takes in true values and predicted values and compares it\n",
    "    Returns: Accuracy,F1-Score,Precision,Recall, Roc-auc Score\n",
    "    \"\"\"\n",
    "    \n",
    "    acc = accuracy_score(true,predicted) # Calcuate Accuracy\n",
    "    f1 = f1_score(true,predicted)\n",
    "    precesion = precision_score(true,predicted)\n",
    "    recall = recall_score(true,predicted)\n",
    "    roc_auc = roc_auc_score(true,predicted)\n",
    "    return acc ,f1,precesion,recall,roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cost of the model as per data description\n",
    "def total_cost(y_true,y_pred):\n",
    "    '''\n",
    "    This function takes y_true and y_predected and prints Total cost due to misclassification \n",
    "    '''\n",
    "    \n",
    "    tn,fp,fn,tp = confusion_matrix(y_true,y_pred).ravel()\n",
    "    cost =10*fp +500*fn\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary which contains models for experiment\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "     \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "#     \"XGBClassifier\": XGBClassifier(), \n",
    "#      \"CatBoosting Classifier\": CatBoostClassifier(verbose=False),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a function which can evaluate model and returns a report\n",
    "\n",
    "def evaluate(X,y,models):\n",
    "    '''\n",
    "    This function takes X ,y and model as input\n",
    "    It splits into train and test\n",
    "    evalute the metrics for train and test\n",
    "    Return: Dataframe which contains report of all models metrics with cost\n",
    "    '''\n",
    "    \n",
    "    X_train,X_test,y_train,y_test =train_test_split(X,y,test_size=0.25,random_state=40)\n",
    "    \n",
    "    cost_list=[]\n",
    "    models_list=[]\n",
    "    accuracy_list=[]\n",
    "    \n",
    "    for i in range(len(list(models))):\n",
    "        model = list(models.values())[i]\n",
    "        print(model)\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "        #Making the Prediction\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        # Training set perforamnce\n",
    "        model_train_acc,model_train_f1,model_train_precission,model_train_recall, \\\n",
    "        model_train_roc = evaluate_model(y_train,y_train_pred)\n",
    "        train_cost= total_cost(y_train,y_train_pred)\n",
    "        \n",
    "        # test set perforamnce\n",
    "        model_test_acc,model_test_f1,model_test_precission,model_test_recall, \\\n",
    "        model_test_roc = evaluate_model(y_test,y_test_pred)\n",
    "        test_cost= total_cost(y_test,y_test_pred)\n",
    "        \n",
    "        print(\"Model Name - \",list(models.keys())[i]) ### It will print the algo name\n",
    "        models_list.append(list(models.keys())[i])\n",
    "        cost_list.append(test_cost)\n",
    "        \n",
    "        \n",
    "        print('######## Model performance for training set ########')\n",
    "        print(f\"Accuracy------------>{model_train_acc}\")\n",
    "        print(f\"F1 score------------>{model_train_f1}\")\n",
    "        print(f\"Precesion----------->{model_train_precission}\")\n",
    "        print(f\"Recall-------------->{model_train_recall}\")\n",
    "        print(f\"Roc Auc Score------->{model_train_roc}\")\n",
    "        \n",
    "        print('######## Model performance for test set ########')\n",
    "        print(f\"Accuracy------------>{model_test_acc}\")\n",
    "        print(f\"F1 score------------>{model_test_f1}\")\n",
    "        print(f\"Precesion----------->{model_test_precission}\")\n",
    "        print(f\"Recall-------------->{model_test_recall}\")\n",
    "        print(f\"Roc Auc Score------->{model_test_roc}\")\n",
    "        print(\"\\n\")\n",
    "    report = pd.DataFrame(list(zip(models_list,cost_list)),columns=['ModelName','Cost']).sort_values(by=['Cost'])\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.drop('class',axis=1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>ag_003</th>\n",
       "      <th>ag_004</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056758.0</td>\n",
       "      <td>4.232800e+04</td>\n",
       "      <td>856.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50394.0</td>\n",
       "      <td>184552.0</td>\n",
       "      <td>2116260.0</td>\n",
       "      <td>8359268.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1450086.0</td>\n",
       "      <td>713608.0</td>\n",
       "      <td>1750894.0</td>\n",
       "      <td>4054554.0</td>\n",
       "      <td>4096660.0</td>\n",
       "      <td>2295880.0</td>\n",
       "      <td>220478.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1665858.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4210.0</td>\n",
       "      <td>847684.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15655546.0</td>\n",
       "      <td>7961190.0</td>\n",
       "      <td>15573746.0</td>\n",
       "      <td>13337708.0</td>\n",
       "      <td>9939694.0</td>\n",
       "      <td>6375252.0</td>\n",
       "      <td>6517696.0</td>\n",
       "      <td>180452.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>341116.0</td>\n",
       "      <td>7.300000e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6782.0</td>\n",
       "      <td>243092.0</td>\n",
       "      <td>2693264.0</td>\n",
       "      <td>10294678.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1392970.0</td>\n",
       "      <td>670836.0</td>\n",
       "      <td>1622420.0</td>\n",
       "      <td>2006306.0</td>\n",
       "      <td>5831812.0</td>\n",
       "      <td>3198600.0</td>\n",
       "      <td>47068.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>207292.0</td>\n",
       "      <td>3.418000e+03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34086.0</td>\n",
       "      <td>300110.0</td>\n",
       "      <td>2063184.0</td>\n",
       "      <td>6215198.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1075284.0</td>\n",
       "      <td>748704.0</td>\n",
       "      <td>1892554.0</td>\n",
       "      <td>2372806.0</td>\n",
       "      <td>3308370.0</td>\n",
       "      <td>176844.0</td>\n",
       "      <td>4860.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1386134.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37938.0</td>\n",
       "      <td>2413744.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11849780.0</td>\n",
       "      <td>6078744.0</td>\n",
       "      <td>11391988.0</td>\n",
       "      <td>9705102.0</td>\n",
       "      <td>10601346.0</td>\n",
       "      <td>5264516.0</td>\n",
       "      <td>6692608.0</td>\n",
       "      <td>634500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34997</th>\n",
       "      <td>37258.0</td>\n",
       "      <td>1.104000e+03</td>\n",
       "      <td>994.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7350.0</td>\n",
       "      <td>...</td>\n",
       "      <td>336870.0</td>\n",
       "      <td>187466.0</td>\n",
       "      <td>402948.0</td>\n",
       "      <td>334876.0</td>\n",
       "      <td>238864.0</td>\n",
       "      <td>123876.0</td>\n",
       "      <td>69168.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34998</th>\n",
       "      <td>26.0</td>\n",
       "      <td>2.130706e+09</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>492.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34999</th>\n",
       "      <td>38024.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>...</td>\n",
       "      <td>289008.0</td>\n",
       "      <td>150976.0</td>\n",
       "      <td>318968.0</td>\n",
       "      <td>206590.0</td>\n",
       "      <td>165736.0</td>\n",
       "      <td>136416.0</td>\n",
       "      <td>347438.0</td>\n",
       "      <td>22926.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35000</th>\n",
       "      <td>11778.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>45020.0</td>\n",
       "      <td>...</td>\n",
       "      <td>404550.0</td>\n",
       "      <td>197372.0</td>\n",
       "      <td>50056.0</td>\n",
       "      <td>12084.0</td>\n",
       "      <td>4608.0</td>\n",
       "      <td>2236.0</td>\n",
       "      <td>2936.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35002 rows Ã— 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          aa_000        ac_000  ad_000  ae_000  af_000  ag_000   ag_001  \\\n",
       "0      1056758.0  4.232800e+04   856.0     0.0     0.0     0.0  50394.0   \n",
       "1      1665858.0           NaN     NaN     0.0     0.0     0.0      0.0   \n",
       "2       341116.0  7.300000e+02     NaN     0.0     0.0     0.0   6782.0   \n",
       "3       207292.0  3.418000e+03     NaN     0.0     0.0     0.0  34086.0   \n",
       "4      1386134.0  0.000000e+00     NaN     0.0     0.0     0.0      0.0   \n",
       "...          ...           ...     ...     ...     ...     ...      ...   \n",
       "34997    37258.0  1.104000e+03   994.0     0.0     0.0     0.0      0.0   \n",
       "34998       26.0  2.130706e+09    16.0     0.0     0.0     0.0      0.0   \n",
       "34999    38024.0  0.000000e+00     NaN     0.0     0.0     0.0      0.0   \n",
       "35000    11778.0  0.000000e+00     NaN     0.0     0.0     0.0      0.0   \n",
       "35001        NaN           NaN     NaN     NaN     NaN     NaN      NaN   \n",
       "\n",
       "         ag_002     ag_003      ag_004  ...      ee_002     ee_003  \\\n",
       "0      184552.0  2116260.0   8359268.0  ...   1450086.0   713608.0   \n",
       "1           0.0     4210.0    847684.0  ...  15655546.0  7961190.0   \n",
       "2      243092.0  2693264.0  10294678.0  ...   1392970.0   670836.0   \n",
       "3      300110.0  2063184.0   6215198.0  ...   1075284.0   748704.0   \n",
       "4           0.0    37938.0   2413744.0  ...  11849780.0  6078744.0   \n",
       "...         ...        ...         ...  ...         ...        ...   \n",
       "34997       0.0        0.0      7350.0  ...    336870.0   187466.0   \n",
       "34998       0.0        0.0        58.0  ...       492.0       16.0   \n",
       "34999       0.0        0.0      1094.0  ...    289008.0   150976.0   \n",
       "35000       0.0       24.0     45020.0  ...    404550.0   197372.0   \n",
       "35001       NaN        NaN         NaN  ...         NaN        NaN   \n",
       "\n",
       "           ee_004      ee_005      ee_006     ee_007     ee_008    ee_009  \\\n",
       "0       1750894.0   4054554.0   4096660.0  2295880.0   220478.0     482.0   \n",
       "1      15573746.0  13337708.0   9939694.0  6375252.0  6517696.0  180452.0   \n",
       "2       1622420.0   2006306.0   5831812.0  3198600.0    47068.0       0.0   \n",
       "3       1892554.0   2372806.0   3308370.0   176844.0     4860.0       0.0   \n",
       "4      11391988.0   9705102.0  10601346.0  5264516.0  6692608.0  634500.0   \n",
       "...           ...         ...         ...        ...        ...       ...   \n",
       "34997    402948.0    334876.0    238864.0   123876.0    69168.0     126.0   \n",
       "34998        46.0        18.0        18.0        0.0        0.0       0.0   \n",
       "34999    318968.0    206590.0    165736.0   136416.0   347438.0   22926.0   \n",
       "35000     50056.0     12084.0      4608.0     2236.0     2936.0       0.0   \n",
       "35001         NaN         NaN         NaN        NaN        NaN       NaN   \n",
       "\n",
       "       ef_000  eg_000  \n",
       "0         0.0     0.0  \n",
       "1         0.0     0.0  \n",
       "2         0.0     0.0  \n",
       "3         0.0     0.0  \n",
       "4         0.0     0.0  \n",
       "...       ...     ...  \n",
       "34997     0.0     0.0  \n",
       "34998     0.0     0.0  \n",
       "34999     0.0     0.0  \n",
       "35000     0.0     0.0  \n",
       "35001     NaN     NaN  \n",
       "\n",
       "[35002 rows x 163 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= X[0:35001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.replace({'pos':1,'neg':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= y.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustscaler = RobustScaler()\n",
    "X1 = robustscaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\likit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\likit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1--->[0.67887549 0.73062857]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\likit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\likit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3--->[0.69373179 0.70388571]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\likit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\likit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5--->[0.7032741  0.69194286]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\likit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\likit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7--->[0.69921719 0.682     ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\likit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\likit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9--->[0.7093309  0.73045714]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "imputer = KNNImputer(n_neighbors=5,weights='uniform',metric='nan_euclidean')\n",
    "strategies =[str(i) for i in [1,3,5,7,9]]\n",
    "for s in strategies:\n",
    "    pipeline = Pipeline(steps=[('i',KNNImputer(n_neighbors=int(s))),('m',LogisticRegression())])\n",
    "    scores = cross_val_score(pipeline,X1,y,scoring='accuracy',cv=2)\n",
    "    results.append(scores)\n",
    "    print(f\"{s}--->{scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1--->   Accuracy - 70.47520321287763\n",
      "3--->   Accuracy - 69.88087505203784\n",
      "5--->   Accuracy - 69.76084778828965\n",
      "7--->   Accuracy - 69.06085937946403\n",
      "9--->   Accuracy - 71.9894019117275\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "for m, i in zip([1,3,5,7,9], results):\n",
    "    print(f\"{m}--->   Accuracy - {mean(i)*100}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **We can observe n_neighbors=9 able to produce highest accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering Basic Steps\n",
    "- 1st step ---- Filling the null values using Imputers(KNNImputer,Mean IMputer,Median Imputer,MICE)\n",
    "- 2nd step ---- Scaling the data and removing outliers(robust scaler)\n",
    "- 3rd step ---- Balancing the target column (SMOTEK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline for KNN imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipeline = Pipeline(\n",
    "steps=[\n",
    "    ('filling_null_values',KNNImputer(n_neighbors=9)),\n",
    "    ('scaling_and_removing_outliers',RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_knn = knn_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\n",
      "     -------------------------------------- 226.0/226.0 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\likit\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.1.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\likit\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\likit\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\likit\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\likit\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.21.5)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.10.1 imblearn-0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "smt = SMOTETomek(random_state=43,sampling_strategy='minority')\n",
    "X_res,y_res =smt.fit_resample(x_knn,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier()\n",
      "Model Name -  Random Forest\n",
      "-----------Model performance for training set-----------\n",
      "Accuracy------------>1.0\n",
      "F1 score------------>1.0\n",
      "Precesion----------->1.0\n",
      "Recall-------------->1.0\n",
      "Roc Auc Score------->1.0\n",
      "-----------Model performance for test set---------------\n",
      "Accuracy------------>0.991451479778328\n",
      "F1 score------------>0.9915751554238567\n",
      "Precesion----------->0.9884165411791961\n",
      "Recall-------------->0.9947540219165306\n",
      "Roc Auc Score------->0.9914132705002501\n",
      "\n",
      "\n",
      "DecisionTreeClassifier()\n",
      "Model Name -  Decision Tree\n",
      "-----------Model performance for training set-----------\n",
      "Accuracy------------>1.0\n",
      "F1 score------------>1.0\n",
      "Precesion----------->1.0\n",
      "Recall-------------->1.0\n",
      "Roc Auc Score------->1.0\n",
      "-----------Model performance for test set---------------\n",
      "Accuracy------------>0.9845537082891168\n",
      "F1 score------------>0.9847886669763121\n",
      "Precesion----------->0.9809160305343512\n",
      "Recall-------------->0.988692002797855\n",
      "Roc Auc Score------->0.9845058296432022\n",
      "\n",
      "\n",
      "GradientBoostingClassifier()\n",
      "Model Name -  Gradient Boosting\n",
      "-----------Model performance for training set-----------\n",
      "Accuracy------------>0.983275685873752\n",
      "F1 score------------>0.9832661488545866\n",
      "Precesion----------->0.9800862406899256\n",
      "Recall-------------->0.9864667587295325\n",
      "Roc Auc Score------->0.9832878059280616\n",
      "-----------Model performance for test set---------------\n",
      "Accuracy------------>0.9812522108241952\n",
      "F1 score------------>0.9815352456160725\n",
      "Precesion----------->0.977788061082832\n",
      "Recall-------------->0.9853112613662859\n",
      "Roc Auc Score------->0.9812052490037535\n",
      "\n",
      "\n",
      "LogisticRegression()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\likit\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name -  Logistic Regression\n",
      "-----------Model performance for training set-----------\n",
      "Accuracy------------>0.627132300919739\n",
      "F1 score------------>0.7189393378268276\n",
      "Precesion----------->0.5755692599620493\n",
      "Recall-------------->0.9574275004931939\n",
      "Roc Auc Score------->0.6283867993088156\n",
      "-----------Model performance for test set---------------\n",
      "Accuracy------------>0.6340054238886924\n",
      "F1 score------------>0.7261337568378332\n",
      "Precesion----------->0.5841022001419447\n",
      "Recall-------------->0.9594311028211704\n",
      "Roc Auc Score------->0.6302403605708906\n",
      "\n",
      "\n",
      "KNeighborsClassifier()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\likit\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\likit\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name -  K-Neighbors Classifier\n",
      "-----------Model performance for training set-----------\n",
      "Accuracy------------>0.9814086942850405\n",
      "F1 score------------>0.9815393021622044\n",
      "Precesion----------->0.9710413529479903\n",
      "Recall-------------->0.9922667192740185\n",
      "Roc Auc Score------->0.9814499342875437\n",
      "-----------Model performance for test set---------------\n",
      "Accuracy------------>0.9734701096568801\n",
      "F1 score------------>0.9741587228666589\n",
      "Precesion----------->0.9599366229062924\n",
      "Recall-------------->0.9888085800885987\n",
      "Roc Auc Score------->0.9732926488229252\n",
      "\n",
      "\n",
      "AdaBoostClassifier()\n",
      "Model Name -  AdaBoost Classifier\n",
      "-----------Model performance for training set-----------\n",
      "Accuracy------------>0.9735869821554909\n",
      "F1 score------------>0.9735193285258306\n",
      "Precesion----------->0.9722932819079854\n",
      "Recall-------------->0.9747484710988361\n",
      "Roc Auc Score------->0.9735913936213865\n",
      "-----------Model performance for test set---------------\n",
      "Accuracy------------>0.9711708524938097\n",
      "F1 score------------>0.9715051570421305\n",
      "Precesion----------->0.9712221833857626\n",
      "Recall-------------->0.9717882956400093\n",
      "Roc Auc Score------->0.971163708888707\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_report = evaluate(X_res,y_res,models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
